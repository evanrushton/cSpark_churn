---
title: "Timespan Classifier 17-18"
author: "Evan Rushton"
date: "10/25/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(corrplot)
library(randomForest)
library(glmnet)
#library(caret)
```

```{r}

# ATTENTION: The data "./Data/ChurnSeg_Past_6_months_.csv" won't work because it is aggregated aross subscription duration. Need to constrain the data during aggregation step in JQL as J.F. did in his pull. "./Data/Churn_5-week_windows_Past_3_months.csv" is not up-to-date with a few factors we want to include and a recent date range
setwd("~/R-projects/codeSpark_churn")
df10 <- read_csv("./Data/trackingWindow_Churn_Prediction-10days.csv")
df10sub <- read_csv("./Data/trackingWindow_Churn_Prediction-10daysub.csv")
df33 <- read_csv("./Data/trackingWindow_Churn_Prediction-33days.csv")
df33sub <- read_csv("./Data/trackingWindow_Churn_Prediction-33daysub.csv")
df65 <- read_csv("./Data/trackingWindow_Churn_Prediction-65days.csv")
df65sub <- read_csv("./Data/trackingWindow_Churn_Prediction-65daysub.csv")
   

one_month_window <- df33sub %>% 
  filter(qa_days_subscribed > 10) %>% 
  select(canceled, time_spent, mission_complete_events, game_maker_drafts, daily_coin_bonus, store_sessions, pet_days, studio_publishes, mission_reload_events, three_starred_levels, minigame_events, clicked_news_events, game_maker_play_events, game_maker_edit_events, parent_portal_tab_events, sandbox_events, app_open_events, snoopy, temple, story_session, did_store, did_minigame, did_pets, did_news, did_game_maker_play, did_game_maker_edit, did_puzzle, did_publish, did_parent_portal, did_snoopy, did_temple, did_story_session)

ten_day_window <- df10sub %>% 
  filter(qa_days_subscribed < 30) %>% 
  select(canceled, time_spent, mission_complete_events, game_maker_drafts, daily_coin_bonus, store_sessions, pet_days, studio_publishes, mission_reload_events, three_starred_levels, minigame_events, clicked_news_events, game_maker_play_events, game_maker_edit_events, parent_portal_tab_events, sandbox_events, app_open_events, snoopy, temple, story_session, did_store, did_minigame, did_pets, did_news, did_game_maker_play, did_game_maker_edit, did_puzzle, did_publish, did_parent_portal, did_snoopy, did_temple, did_story_session)
```

# Check Data Quality

```{r}
df <- one_month_window
sapply(df, function(y) length(which(is.na(y))))
xtabs(~ canceled + round(qa_days_subscribed), data=df)
table(as.Date(df$qa_subscription_date))
table(as.Date(df$qa_last_event_date))
xtabs(~ canceled + converted_from_trial, data=df)
xtabs(~ canceled + did_store, data=df)
xtabs(~ canceled + did_minigame, data=df)
xtabs(~ canceled + did_pets, data=df)
xtabs(~ canceled + did_news, data=df)
xtabs(~ canceled + did_game_maker_play, data=df)
xtabs(~ canceled + did_game_maker_edit, data=df)
xtabs(~ canceled + did_puzzle, data=df)
xtabs(~ canceled + did_publish, data=df)
xtabs(~ canceled + did_parent_portal, data=df)
xtabs(~ canceled + did_snoopy, data=df)
xtabs(~ canceled + did_temple, data=df)
xtabs(~ canceled + did_story_session, data=df)


xtabs(~ as.Date(qa_subscription_date) + did_story_session, data=df33)

```



```{r}
# ===== Visualize Vars =====
df <- df10sub
#Histograms to check distributions of numerical vars
par(mfrow = c(3, 2)) 
hist(df$time_spent / 60, main=paste("Minutes Played (N= ",length(df$time_spent),")", sep=""), xlab="")
hist(df$time_spent[which(df$time_spent < 14400)] / 60, main=paste("Under 240 mins (N= ",length(df$time_spent[which(df$time_spent < 14400)]),")", sep=""), xlab="")
hist(df$time_spent[which(df$time_spent < 7200)] / 60, main=paste("Under 120 mins (N= ",length(df$time_spent[which(df$time_spent < 7200)]),")", sep=""), xlab="") 
hist(df$time_spent[which(df$time_spent < 3600)] / 60, main=paste("Under 60 mins (N= ",length(df$time_spent[which(df$time_spent < 3600)]),")", sep=""), xlab="") 
hist(df$time_spent[which(df$time_spent < 2400)] / 60, main=paste("Under 40 mins (N= ",length(df$time_spent[which(df$time_spent < 2400)]),")", sep=""), xlab="") 
hist(df$time_spent[which(df$time_spent < 1200)] / 60, main=paste("Under 20 mins (N= ",length(df$time_spent[which(df$time_spent < 1200)]),")", sep=""), xlab="") 


hist(df$mission_complete_events , main=paste("Mission Complete (N= ",length(df$mission_complete_events),")", sep=""), xlab="")
hist(df$mission_complete_events[which(df$mission_complete_events < 500)] , main=paste("Under 500 complete (N= ",length(df$mission_complete_events[which(df$mission_complete_events < 500)]),")", sep=""), xlab="")
hist(df$mission_complete_events[which(df$mission_complete_events < 50)] , main=paste("Under 50 complete (N= ",length(df$mission_complete_events[which(df$mission_complete_events < 50)]),")", sep=""), xlab="")
hist(df$mission_complete_events[which(df$mission_complete_events < 20)] , main=paste("Under 20 complete (N= ",length(df$mission_complete_events[which(df$mission_complete_events < 20)]),")", sep=""), xlab="")
hist(df$mission_complete_events[which(df$mission_complete_events < 10)] , main=paste("Under 10 complete (N= ",length(df$mission_complete_events[which(df$mission_complete_events < 10)]),")", sep=""), xlab="")
hist(df$mission_complete_events[which(df$mission_complete_events < 5)] , main=paste("Under 5 complete (N= ",length(df$mission_complete_events[which(df$mission_complete_events < 5)]),")", sep=""), xlab="")


hist(df$qa_days_subscribed, main="Subscription Duration (days)")
hist(df$qa_days_subscribed[which(df$qa_days_subscribed < 40)], main="Subscription Duration (Under 40 days)")

#Counts to check distributions of categorical vars

hist(as.Date(df$qa_subscription_date), breaks="weeks", freq=TRUE)
hist(df$create_profile_events)
hist(df$value.completed_puzzle)
hist(log(df$value.completed_puzzle))
table(df$value.account_Status)
table(df$daily_coin_bonus)


```

# What does the distribution of subscriptions over time look like?

```{r}
df <- df10

df %>% 
  ggplot(aes(x=as.Date(qa_subscription_date), y=time_spent)) +
  geom_point()

```

# Logistic Regression
```{r}
logistic <- glm(canceled ~ ., data=ten_day_window, family = "binomial")
summary(logistic10)


logistic33 <- glm(canceled ~ ., data=one_month_window, family = "binomial")
summary(logistic33)

# Log-likelihood (psuedo R-squared)
ll.null <- logistic$null.deviance/-2
ll.proposed <- logistic$deviance/-2
(ll.null - ll.proposed) / ll.null # overall effect size
1-pchisq(2*(ll.proposed - ll.null), df=(length(logistic$coefficients)-1))

# Plot
df <- ten_day_window
predicted.data <- data.frame(
  probability.of.canceled=logistic$fitted.values,
  canceled=df$canceled)

predicted.data <- predicted.data[
  order(predicted.data$probability.of.canceled, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)
library(ggplot2)
library(cowplot)
ggplot(data=predicted.data, aes(x=rank, y=probability.of.canceled)) +
  geom_point(aes(color=canceled), alpha=1, shape=4, stroke=2) +
  xlab("Index") +
  ylab("Predicted probability of getting canceled")
 
```

